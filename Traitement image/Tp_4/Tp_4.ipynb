{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP4 : Classification d'Images avec SVM et Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activité 1 : Entraînement du modèle SVM\n",
    "\n",
    "Extraire les descripteurs SIFT, créer un vocabulaire visuel avec K-means, calculer les histogrammes et entraîner un modèle SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total d'images : 409, Classes : 3\n",
      "Nombre total de descripteurs : (63549, 128)\n",
      "Modèle SVM entraîné et sauvegardé sous bof_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from skimage.feature import SIFT\n",
    "from PIL import Image\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# Étape 1 : Lister les images et attribuer des identifiants de classe\n",
    "train_path = 'images/dataset/train'\n",
    "training_names = os.listdir(train_path)\n",
    "image_paths = []\n",
    "image_classes = []\n",
    "class_id = 0\n",
    "\n",
    "def imglist(path):\n",
    "    # Retourne la liste des chemins d'images avec extensions .jpg ou .png\n",
    "    return [os.path.join(path, f) for f in os.listdir(path) if f.endswith(('.jpg', '.png'))]\n",
    "\n",
    "for training_name in training_names:\n",
    "    dir_path = os.path.join(train_path, training_name)\n",
    "    if os.path.isdir(dir_path):\n",
    "        class_path = imglist(dir_path)\n",
    "        image_paths += class_path\n",
    "        image_classes += [class_id] * len(class_path)\n",
    "        class_id += 1\n",
    "\n",
    "print(f'Nombre total d\\'images : {len(image_paths)}, Classes : {class_id}')\n",
    "\n",
    "# Étape 2 : Extraire les descripteurs SIFT\n",
    "descriptor_extractor = SIFT()\n",
    "des_list = []\n",
    "\n",
    "for image_path in image_paths:\n",
    "    im = np.array(Image.open(image_path).convert('L').resize((128, 128)))\n",
    "    try:\n",
    "        descriptor_extractor.detect_and_extract(im)\n",
    "        descriptors = descriptor_extractor.descriptors\n",
    "        if descriptors is not None and len(descriptors) > 0:\n",
    "            des_list.append((image_path, descriptors))\n",
    "    except:\n",
    "        print(f'Échec de l\\'extraction des descripteurs pour {image_path}')\n",
    "\n",
    "# Empiler tous les descripteurs\n",
    "descriptors = des_list[0][1]\n",
    "for _, descriptor in des_list[1:]:\n",
    "    descriptors = np.vstack((descriptors, descriptor))\n",
    "\n",
    "print(f'Nombre total de descripteurs : {descriptors.shape}')\n",
    "\n",
    "# Étape 3 : Créer un vocabulaire visuel avec K-means\n",
    "k = 100  # Nombre initial de clusters\n",
    "kmeans = KMeans(n_clusters=k, random_state=30)\n",
    "kmeans.fit(descriptors)\n",
    "codebook = kmeans.cluster_centers_\n",
    "\n",
    "# Étape 4 : Calculer les histogrammes BoF\n",
    "im_features = np.zeros((len(image_paths), k), 'float32')\n",
    "for i in range(len(image_paths)):\n",
    "    if i < len(des_list):\n",
    "        words = kmeans.predict(des_list[i][1])\n",
    "        for w in words:\n",
    "            im_features[i][w] += 1\n",
    "\n",
    "# Normaliser les caractéristiques\n",
    "stdslr = StandardScaler().fit(im_features)\n",
    "im_features = stdslr.transform(im_features)\n",
    "\n",
    "# Étape 5 : Entraîner le SVM\n",
    "clf = LinearSVC(max_iter=10000, random_state=30)\n",
    "clf.fit(im_features, np.array(image_classes))\n",
    "\n",
    "# Étape 6 : Sauvegarder le modèle\n",
    "joblib.dump((clf, training_names, stdslr, k, codebook), 'bof_model.pkl', compress=3)\n",
    "print('Modèle SVM entraîné et sauvegardé sous bof_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activité 2 : Prédiction de la classe d'une image\n",
    "\n",
    "Nous allons charger le modèle sauvegardé, extraire les caractéristiques d'une image de test et prédire sa classe. Ensuite, nous ré-entraînerons le modèle avec k=50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe prédite pour l'image de test : sea\n",
      "Modèle SVM ré-entraîné avec k=50 et sauvegardé sous bof_model_k50.pkl\n"
     ]
    }
   ],
   "source": [
    "# Étape 1 : Charger le modèle sauvegardé\n",
    "clf, classes_names, stdslr, k, codebook = joblib.load('bof_model.pkl')\n",
    "\n",
    "# Étape 2 : Extraire les descripteurs SIFT de l'image de test\n",
    "test_path = 'images/dataset/test/sea/sea_test-001.jpg'\n",
    "im = np.array(Image.open(test_path).convert('L').resize((128, 128)))\n",
    "descriptor_extractor.detect_and_extract(im)\n",
    "test_descriptors = descriptor_extractor.descriptors\n",
    "\n",
    "# Étape 3 : Calculer l'histogramme BoF pour l'image de test\n",
    "test_features = np.zeros((1, k), 'float32')\n",
    "if test_descriptors is not None:\n",
    "    words = kmeans.predict(test_descriptors)\n",
    "    for w in words:\n",
    "        test_features[0][w] += 1\n",
    "\n",
    "# Normaliser les caractéristiques de test\n",
    "test_features = stdslr.transform(test_features)\n",
    "\n",
    "# Étape 4 : Prédire la classe\n",
    "prediction = clf.predict(test_features)\n",
    "predicted_class = classes_names[prediction[0]]\n",
    "print(f'Classe prédite pour l\\'image de test : {predicted_class}')\n",
    "\n",
    "# Étape 5 : Ré-entraîner avec k=50\n",
    "k = 50\n",
    "kmeans = KMeans(n_clusters=k, random_state=30)\n",
    "kmeans.fit(descriptors)\n",
    "codebook = kmeans.cluster_centers_\n",
    "\n",
    "im_features = np.zeros((len(image_paths), k), 'float32')\n",
    "for i in range(len(image_paths)):\n",
    "    if i < len(des_list):\n",
    "        words = kmeans.predict(des_list[i][1])\n",
    "        for w in words:\n",
    "            im_features[i][w] += 1\n",
    "\n",
    "stdslr = StandardScaler().fit(im_features)\n",
    "im_features = stdslr.transform(im_features)\n",
    "\n",
    "clf = LinearSVC(max_iter=10000, random_state=30)\n",
    "clf.fit(im_features, np.array(image_classes))\n",
    "\n",
    "joblib.dump((clf, training_names, stdslr, k, codebook), 'bof_model_k50.pkl', compress=3)\n",
    "print('Modèle SVM ré-entraîné avec k=50 et sauvegardé sous bof_model_k50.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activité 3 : Utiliser l'algorithme Random Forest\n",
    "\n",
    "Nous allons entraîner un classificateur Random Forest avec les mêmes caractéristiques et comparer ses performances avec le SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle Random Forest entraîné et sauvegardé sous bof_rf_model.pkl\n",
      "Random Forest predicted class for test image: sea\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# # Entraîner Random Forest\n",
    "clf_rf = RandomForestClassifier(n_estimators=100, random_state=30)\n",
    "clf_rf.fit(im_features, np.array(image_classes))\n",
    "\n",
    "# # Sauvegarder le modèle Random Forest\n",
    "joblib.dump((clf_rf, training_names, stdslr, k, codebook), 'bof_rf_model.pkl', compress=3)\n",
    "print('Modèle Random Forest entraîné et sauvegardé sous bof_rf_model.pkl')\n",
    "\n",
    "# # Prédire avec Random Forest\n",
    "# Recalculate test features using k=50\n",
    "test_features_k50 = np.zeros((1, k), 'float32')\n",
    "if test_descriptors is not None:\n",
    "\twords_k50 = kmeans.predict(test_descriptors)\n",
    "\tfor w in words_k50:\n",
    "\t\ttest_features_k50[0][w] += 1\n",
    "\n",
    "# Normalize the test features\n",
    "test_features_k50 = stdslr.transform(test_features_k50)\n",
    "\n",
    "# Predict with Random Forest\n",
    "prediction_rf = clf_rf.predict(test_features_k50)\n",
    "predicted_class_rf = classes_names[prediction_rf[0]]\n",
    "print(f'Random Forest predicted class for test image: {predicted_class_rf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison des résultats\n",
    "\n",
    "**SVM vs Random Forest** :\n",
    "- **SVM** : Efficace pour les données à haute dimension comme les histogrammes BoF, particulièrement avec des noyaux linéaires. Il performe mieux lorsque les classes sont bien séparées.\n",
    "- **Random Forest** : Robuste au surajustement, gère bien les relations non linéaires et est moins sensible à la mise à l'échelle des caractéristiques. Il peut surpasser le SVM dans les cas de frontières de classe complexes.\n",
    "- **Pertinence** : La pertinence des prédictions dépend du dataset. Si la classe prédite pour l'image de test correspond à la classe attendue (basée sur la similarité visuelle ou la vérité terrain), le modèle est considéré comme précis. Random Forest peut offrir une meilleure généralisation pour des datasets bruités ou variés, tandis que le SVM peut être plus précis pour des datasets plus petits et bien structurés.\n",
    "- **Impact de k=50** : Réduire k de 100 à 50 diminue la taille du vecteur de caractéristiques, ce qui peut simplifier le modèle mais risque de perdre en pouvoir discriminant. L'effet dépend de la complexité du dataset.\n",
    "\n",
    "Pour une comparaison quantitative, il serait idéal de diviser les données d'entraînement en ensembles d'entraînement/validation et de calculer la précision. Cependant, avec une seule image de test, la comparaison est qualitative (prédiction correcte/incorrecte)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

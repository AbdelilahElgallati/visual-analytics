{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification d'images avec SVM et caractéristiques HOG sur CIFAR-10\n",
    "\n",
    "Ce notebook présente un pipeline complet pour la classification binaire d'images (chats vs chiens) en utilisant un classificateur SVM avec des caractéristiques HOG sur le jeu de données CIFAR-10. Chaque étape est expliquée ci-dessous, incluant le chargement des données, l'extraction des caractéristiques, l'entraînement du modèle, l'évaluation et la visualisation.\n",
    "\n",
    "## Pourquoi choisir CIFAR-10 ?\n",
    "- **Description** : CIFAR-10 contient 60 000 images RGB de 32x32 pixels dans 10 classes (avion, voiture, oiseau, chat, chien, etc.), avec 50 000 images d'entraînement et 10 000 de test.\n",
    "- **Accessibilité** : Disponible via `tensorflow.keras.datasets.cifar10`, sans téléchargement manuel.\n",
    "- **Pertinence** : La petite taille des images (32x32) est idéale pour l'extraction HOG, et le jeu de données supporte la classification binaire (chats vs chiens).\n",
    "\n",
    "## Aperçu du pipeline\n",
    "1. **Chargement et prétraitement** : Charger CIFAR-10, sélectionner les images de chats et chiens, convertir en niveaux de gris.\n",
    "2. **Extraction HOG** : Calculer les descripteurs HOG pour chaque image.\n",
    "3. **Préparation des données** : Créer des ensembles d'entraînement/test équilibrés, standardiser les caractéristiques.\n",
    "4. **Entraînement SVM** : Utiliser un classificateur SVM linéaire.\n",
    "5. **Évaluation** : Calculer l'exactitude, le rapport de classification et la matrice de confusion.\n",
    "6. **Visualisation** : Afficher la matrice de confusion et des prédictions d'échantillons.\n",
    "\n",
    "## Prérequis\n",
    "Installez les bibliothèques nécessaires :\n",
    "```bash\n",
    "pip install numpy opencv-python scikit-learn scikit-image tensorflow matplotlib seaborn\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # Supprimer les avertissements pour un affichage propre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 1 : Extraction des caractéristiques HOG\n",
    "\n",
    "La fonction `extract_hog_features` calcule les descripteurs HOG pour une image :\n",
    "- **Entrée** : Une image RGB ou en niveaux de gris.\n",
    "- **Traitement** : Convertit en niveaux de gris, extrait les caractéristiques HOG avec des paramètres spécifiés.\n",
    "- **Paramètres** :\n",
    "  - `orientations=8` : Nombre de bins pour les orientations de gradient.\n",
    "  - `pixels_per_cell=(8, 8)` : Taille de chaque cellule (8x8 pixels).\n",
    "  - `cells_per_block=(2, 2)` : Taille de chaque bloc (2x2 cellules) pour la normalisation.\n",
    "- **Sortie** : Un vecteur de caractéristiques 1D (par exemple, 288 caractéristiques pour une image 32x32).\n",
    "\n",
    "**Taille du vecteur de caractéristiques** (pour une image 32x32) :\n",
    "- Cellules : `(32/8) x (32/8) = 4x4 = 16` cellules.\n",
    "- Blocs : `(4-2+1) x (4-2+1) = 3x3 = 9` blocs.\n",
    "- Caractéristiques par bloc : `2x2 cellules * 8 orientations = 32`.\n",
    "- Total : `9 blocs * 32 = 288` caractéristiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour extraire les caractéristiques HOG d'une image\n",
    "def extract_hog_features(img, pixels_per_cell=(8, 8), cells_per_block=(2, 2), orientations=8):\n",
    "    # Convertir en niveaux de gris si l'image est RGB\n",
    "    if len(img.shape) == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Calculer les caractéristiques HOG\n",
    "    fd = hog(\n",
    "        img,\n",
    "        orientations=orientations,\n",
    "        pixels_per_cell=pixels_per_cell,\n",
    "        cells_per_block=cells_per_block,\n",
    "        visualize=False\n",
    "    )\n",
    "    return fd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 2 : Chargement et prétraitement de CIFAR-10\n",
    "\n",
    "La fonction `load_cifar10_binary` prépare le jeu de données pour la classification binaire :\n",
    "- Charge CIFAR-10 avec `cifar10.load_data()`.\n",
    "- Sélectionne les images de chats (étiquette 3) et de chiens (étiquette 5).\n",
    "- Attribue des étiquettes binaires : 1 pour les chats, 0 pour les chiens.\n",
    "- Limite à 1000 images par classe pour l'entraînement et 200 par classe pour le test pour équilibrer calcul et performance.\n",
    "- Retourne des tableaux numpy pour les images et les étiquettes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour charger CIFAR-10 pour la classification binaire (chats vs chiens)\n",
    "def load_cifar10_binary(num_train_per_class=1000, num_test_per_class=200):\n",
    "    # Charger le jeu de données CIFAR-10\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "    \n",
    "    # Étiquettes CIFAR-10 : 3 = chat, 5 = chien\n",
    "    cat_label, dog_label = 3, 5\n",
    "    X_train_binary, y_train_binary = [], []\n",
    "    X_test_binary, y_test_binary = [], []\n",
    "    \n",
    "    # Sélectionner les images de chats et chiens pour l'entraînement\n",
    "    cat_count, dog_count = 0, 0\n",
    "    for i in range(len(X_train)):\n",
    "        if y_train[i] == cat_label and cat_count < num_train_per_class:\n",
    "            X_train_binary.append(X_train[i])\n",
    "            y_train_binary.append(1)  # Chat = 1\n",
    "            cat_count += 1\n",
    "        elif y_train[i] == dog_label and dog_count < num_train_per_class:\n",
    "            X_train_binary.append(X_train[i])\n",
    "            y_train_binary.append(0)  # Chien = 0\n",
    "            dog_count += 1\n",
    "        if cat_count >= num_train_per_class and dog_count >= num_train_per_class:\n",
    "            break\n",
    "    \n",
    "    # Sélectionner les images de chats et chiens pour le test\n",
    "    cat_count, dog_count = 0, 0\n",
    "    for i in range(len(X_test)):\n",
    "        if y_test[i] == cat_label and cat_count < num_test_per_class:\n",
    "            X_test_binary.append(X_test[i])\n",
    "            y_test_binary.append(1)  # Chat = 1\n",
    "            cat_count += 1\n",
    "        elif y_test[i] == dog_label and dog_count < num_test_per_class:\n",
    "            X_test_binary.append(X_test[i])\n",
    "            y_test_binary.append(0)  # Chien = 0\n",
    "            dog_count += 1\n",
    "        if cat_count >= num_test_per_class and dog_count >= num_test_per_class:\n",
    "            break\n",
    "    \n",
    "    return (np.array(X_train_binary), np.array(y_train_binary),\n",
    "            np.array(X_test_binary), np.array(y_test_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 3 : Visualisation des prédictions\n",
    "\n",
    "La fonction `visualize_predictions` affiche des images de test avec leurs étiquettes réelles et prédites :\n",
    "- Sélectionne aléatoirement 6 images de test.\n",
    "- Affiche chaque image avec son étiquette réelle (Chat ou Chien) et prédite.\n",
    "- Utilise Matplotlib pour un affichage en grille."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour visualiser les prédictions d'échantillons\n",
    "def visualize_predictions(X_test, y_test, y_pred, num_samples=6):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    indices = np.random.choice(len(X_test), num_samples, replace=False)\n",
    "    for i, idx in enumerate(indices):\n",
    "        plt.subplot(2, num_samples//2, i+1)\n",
    "        plt.imshow(X_test[idx])\n",
    "        plt.title(f\"Vrai : {'Chat' if y_test[idx] == 1 else 'Chien'}\\nPrédit : {'Chat' if y_pred[idx] == 1 else 'Chien'}\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 4 : Pipeline principal\n",
    "\n",
    "Le pipeline principal :\n",
    "- Charge et prétraite les données.\n",
    "- Extrait les caractéristiques HOG pour toutes les images.\n",
    "- Standardise les caractéristiques pour améliorer les performances du SVM.\n",
    "- Entraîne un classificateur SVM linéaire.\n",
    "- Évalue le modèle avec l'exactitude, le rapport de classification et la matrice de confusion.\n",
    "- Visualise les résultats.\n",
    "\n",
    "**Performance attendue** :\n",
    "- Exactitude : ~60-70% en raison de la complexité de CIFAR-10 (basse résolution, fonds variés).\n",
    "- Améliorations possibles : ajuster les paramètres HOG, utiliser un noyau non linéaire, augmenter les données d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du jeu de données CIFAR-10...\n",
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m 17301504/170498071\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:11:16\u001b[0m 51us/step"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Charger et prétraiter les données\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChargement du jeu de données CIFAR-10...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m X_train, y_train, X_test, y_test \u001b[38;5;241m=\u001b[39m load_cifar10_binary(\n\u001b[0;32m      8\u001b[0m     num_train_per_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, num_test_per_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Extraire les caractéristiques HOG\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtraction des caractéristiques HOG...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m, in \u001b[0;36mload_cifar10_binary\u001b[1;34m(num_train_per_class, num_test_per_class)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_cifar10_binary\u001b[39m(num_train_per_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, num_test_per_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Charger le jeu de données CIFAR-10\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     (X_train, y_train), (X_test, y_test) \u001b[38;5;241m=\u001b[39m cifar10\u001b[38;5;241m.\u001b[39mload_data()\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Étiquettes CIFAR-10 : 3 = chat, 5 = chien\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     cat_label, dog_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\dell\\anaconda3\\Lib\\site-packages\\keras\\src\\datasets\\cifar10.py:65\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     63\u001b[0m dirname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcifar-10-batches-py-target\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     64\u001b[0m origin \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 65\u001b[0m path \u001b[38;5;241m=\u001b[39m get_file(\n\u001b[0;32m     66\u001b[0m     fname\u001b[38;5;241m=\u001b[39mdirname,\n\u001b[0;32m     67\u001b[0m     origin\u001b[38;5;241m=\u001b[39morigin,\n\u001b[0;32m     68\u001b[0m     extract\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     69\u001b[0m     file_hash\u001b[38;5;241m=\u001b[39m(  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m6d958be074577803d12ecdefd02955f39262c83c16fe9348329d7fe0b5c001ce\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m     ),\n\u001b[0;32m     72\u001b[0m )\n\u001b[0;32m     74\u001b[0m num_train_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50000\u001b[39m\n\u001b[0;32m     76\u001b[0m x_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((num_train_samples, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dell\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\file_utils.py:311\u001b[0m, in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir, force_download)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 311\u001b[0m         urlretrieve(origin, download_target, DLProgbar())\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(error_msg\u001b[38;5;241m.\u001b[39mformat(origin, e\u001b[38;5;241m.\u001b[39mcode, e\u001b[38;5;241m.\u001b[39mmsg))\n",
      "File \u001b[1;32mc:\\Users\\dell\\anaconda3\\Lib\\urllib\\request.py:268\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reporthook:\n\u001b[0;32m    266\u001b[0m     reporthook(blocknum, bs, size)\n\u001b[1;32m--> 268\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m block \u001b[38;5;241m:=\u001b[39m fp\u001b[38;5;241m.\u001b[39mread(bs):\n\u001b[0;32m    269\u001b[0m     read \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(block)\n\u001b[0;32m    270\u001b[0m     tfp\u001b[38;5;241m.\u001b[39mwrite(block)\n",
      "File \u001b[1;32mc:\\Users\\dell\\anaconda3\\Lib\\http\\client.py:479\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    478\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[1;32m--> 479\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[0;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mc:\\Users\\dell\\anaconda3\\Lib\\socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dell\\anaconda3\\Lib\\ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\dell\\anaconda3\\Lib\\ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Pipeline principal\n",
    "# Définir une graine aléatoire pour la reproductibilité\n",
    "np.random.seed(42)\n",
    "\n",
    "# Charger et prétraiter les données\n",
    "print(\"Chargement du jeu de données CIFAR-10...\")\n",
    "X_train, y_train, X_test, y_test = load_cifar10_binary(\n",
    "    num_train_per_class=1000, num_test_per_class=200\n",
    ")\n",
    "\n",
    "# Extraire les caractéristiques HOG\n",
    "print(\"Extraction des caractéristiques HOG...\")\n",
    "X_train_hog = [extract_hog_features(img) for img in X_train]\n",
    "X_test_hog = [extract_hog_features(img) for img in X_test]\n",
    "\n",
    "# Convertir en tableaux numpy\n",
    "X_train_hog = np.array(X_train_hog)\n",
    "X_test_hog = np.array(X_test_hog)\n",
    "\n",
    "# Standardiser les caractéristiques\n",
    "print(\"Standardisation des caractéristiques...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_hog = scaler.fit_transform(X_train_hog)\n",
    "X_test_hog = scaler.transform(X_test_hog)\n",
    "\n",
    "# Entraîner le classificateur SVM\n",
    "print(\"Entraînement du classificateur SVM...\")\n",
    "svm = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "svm.fit(X_train_hog, y_train)\n",
    "\n",
    "# Évaluer le modèle\n",
    "print(\"Évaluation du modèle...\")\n",
    "y_pred = svm.predict(X_test_hog)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Exactitude : {accuracy:.4f}\")\n",
    "print(\"\\nRapport de classification :\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Chien', 'Chat']))\n",
    "\n",
    "# Afficher la matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Chien', 'Chat'], yticklabels=['Chien', 'Chat'])\n",
    "plt.title('Matrice de confusion')\n",
    "plt.xlabel('Prédit')\n",
    "plt.ylabel('Vrai')\n",
    "plt.show()\n",
    "\n",
    "# Visualiser les prédictions d'échantillons\n",
    "print(\"Visualisation des prédictions d'échantillons...\")\n",
    "visualize_predictions(X_test, y_test, y_pred, num_samples=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes et extensions\n",
    "\n",
    "- **Amélioration des performances** :\n",
    "  - Ajuster les paramètres HOG (par exemple, `pixels_per_cell=(4, 4)`, `orientations=9`).\n",
    "  - Utiliser un noyau non linéaire (par exemple, `kernel='rbf'`) ou optimiser `C` avec `GridSearchCV`.\n",
    "  - Augmenter les données d'entraînement (par exemple, 5000 images par classe).\n",
    "  - Normaliser les images avant HOG (par exemple, `img = img / 255.0`).\n",
    "- **Extension à la classification multi-classe** :\n",
    "  - Inclure les 10 classes de CIFAR-10.\n",
    "  - Utiliser `OneVsRestClassifier(SVC())` pour un SVM multi-classe.\n",
    "- **Jeux de données alternatifs** :\n",
    "  - **MNIST** : Chiffres manuscrits (28x28), via `tensorflow.keras.datasets.mnist`.\n",
    "  - **Oxford-IIIT Pet** : Chats vs chiens, nécessite un téléchargement manuel.\n",
    "  - **Fashion-MNIST** : Vêtements, via `tensorflow.keras.datasets.fashion_mnist`.\n",
    "- **Dépannage** :\n",
    "  - Réduire `num_train_per_class` en cas de problèmes de mémoire.\n",
    "  - Vérifier la cohérence des tailles des caractéristiques HOG.\n",
    "\n",
    "**Citation** : Krizhevsky, A. (2009). Learning Multiple Layers of Features from Tiny Images. [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
